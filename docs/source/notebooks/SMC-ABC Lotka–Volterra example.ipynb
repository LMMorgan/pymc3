{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Monte Carlo - Approximate Bayesian Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate Bayesian Computation methods (also called likelihood free inference methods), are a group of techniques developed for inferring posterior distributions in cases where the likelihood function is intractable or costly to evaluate. This does not mean that the likelihood function is not part of the analysis, rather that it is not directly evaluated. \n",
    "\n",
    "ABC comes useful when modelling complex phenomena in certain fields of study, like systems biology. Such models often contain unobservable random quantities, which make the likelihood function hard to specify, but data can be simulated from the model.  \n",
    "\n",
    "These methods follow a general form:\n",
    "\n",
    "1- Sample a parameter $\\theta^*$ from a prior/proposal distribution $\\pi(\\theta)$.\n",
    "\n",
    "2- Simulate a data set $y^*$ using a function that takes $\\theta$ and returns a data set of the same dimensions as the observed data set $y_0$ (simulator).\n",
    "\n",
    "3- Compare the simulated dataset $y^*$ with the experimental data set $y_0$ using a distance function $d$ and a tolerance threshold $\\epsilon$. \n",
    "\n",
    "\n",
    "In some cases a distance function is computed between two summary statistics $d(S(y_0), S(y^*))$, avoiding the issue of computing distances for entire datasets.\n",
    "\n",
    "As a result we obtain a sample of parameters from a distribution $\\pi(\\theta | d(y_0, y^*)) \\leqslant \\epsilon$. \n",
    "\n",
    "If $\\epsilon$ is sufficiently small this distribution will be a good approximation of the posterior distribution $\\pi(\\theta | y_0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sequential monte carlo](https://docs.pymc.io/notebooks/SMC2_gaussians.html?highlight=smc) ABC is a method that iteratevly morphs the prior into a posterior by propagating the sampled parameters through a series of proposal distributions $\\phi(\\theta^{(i)})$, weighting the accepted parameters $\\theta^{(i)}$ like:\n",
    "\n",
    "$$ w^{(i)} \\propto \\frac{\\pi(\\theta^{(i)})}{\\phi(\\theta^{(i)})} $$\n",
    "\n",
    "It combines the advantages of traditional SMC, i.e. ability to sample from distributions with multiple peaks, but without the need for evaluating the likelihood function. \n",
    "\n",
    "_(Lintusaari, 2016), (Toni, T., 2008), (Nuñez, Prangle, 2015)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A trivial example\n",
    "Estimating the mean and standard deviation of normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(loc=0, scale=1, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_sim(a, b):\n",
    "    return np.sort(np.random.normal(a, b, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample initial stage: ...\n",
      "Stage: 0 Beta: 0.003 Steps: 25\n",
      "Stage: 1 Beta: 0.026 Steps: 7\n",
      "Stage: 2 Beta: 0.110 Steps: 3\n",
      "Stage: 3 Beta: 0.363 Steps: 5\n",
      "Stage: 4 Beta: 1.000 Steps: 4\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as example:\n",
    "    a = pm.Normal('a', mu=0, sd=5)\n",
    "    b = pm.HalfNormal('b', sd=1)\n",
    "    s = pm.Simulator('s', normal_sim, observed=np.sort(data))\n",
    "    trace_example = pm.sample(step=pm.SMC(ABC=True, epsilon=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace_example);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10,4))\n",
    "az.plot_kde(data, label='True data', ax=ax, plot_kwargs={'color':'C2'})\n",
    "az.plot_kde(normal_sim(trace_example['a'].mean(), trace_example['b'].mean()), ax=ax)\n",
    "for i in np.random.randint(0, 500, 25):\n",
    "    az.plot_kde(normal_sim(trace_example['a'][i], trace_example['b'][i]), ax=ax, plot_kwargs={'zorder':0, 'alpha':0.2})\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lotka–Volterra\n",
    "In this example we will try to find parameters for the Lotka-Volterra equations. A common biological competition model for describing how the number of individuals of each species changes when there is a predator/prey interaction (A Biologist’s Guide to Mathematical Modeling in Ecology and Evolution,Otto and Day, 2007). For example, rabbits and foxes. Given an initial population number for each species, the integration of this ordinary differential equations (ODE) describes curves for the progression of both populations. This ODE’s takes four parameters:\n",
    "\n",
    "*    a is the natural growing rate of rabbits, when there’s no fox.\n",
    "*    b is the natural dying rate of rabbits, due to predation.\n",
    "*    c is the natural dying rate of fox, when there’s no rabbit.\n",
    "*    d is the factor describing how many caught rabbits let create a new fox.\n",
    "\n",
    "This example is based on the Scipy Lokta-Volterra Tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will generate data using known parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of parameters\n",
    "a = 1.\n",
    "b = 0.1\n",
    "c = 1.5\n",
    "d = 0.75\n",
    "\n",
    "# initial population of rabbits and foxes\n",
    "X0 = [10., 5.]\n",
    "# size of data\n",
    "size = 100\n",
    "# time lapse\n",
    "time = 15\n",
    "t = np.linspace(0, time, size)\n",
    "\n",
    "# Lotka - Volterra equation\n",
    "def dX_dt(X, t, a, b, c, d):\n",
    "    \n",
    "    \"\"\" Return the growth rate of fox and rabbit populations. \"\"\"\n",
    "\n",
    "    return np.array([a*X[0] - b*X[0]*X[1], \n",
    "                  -c*X[1] + d*b*X[0]*X[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is based on a simulator, a function that returns data in the same dimensions as the observed data. In this case, the function solves the ODE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator function\n",
    "def competition_model(a, b): \n",
    "    return odeint(dX_dt, y0=X0, t=t, rtol=0.1, args=(a, b, c, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the simulator function we will obtain a dataset with some noise added, for using it as observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating noisy data to be used as observed data.\n",
    "def add_noise(a, b, c, d):\n",
    "    noise = np.random.normal(size=(size, 2))\n",
    "    simulated = competition_model(a, b)\n",
    "    simulated += noise\n",
    "    indexes = np.sort(np.random.randint(low=0, high=size, size=size))    \n",
    "    return simulated[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting observed data.\n",
    "observed = add_noise(a, b, c, d )\n",
    "_, ax = plt.subplots(figsize=(12,4))\n",
    "ax.plot(observed[:,0], 'x', label='prey')\n",
    "ax.plot(observed[:,1], 'x', label='predator')\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('population')\n",
    "ax.set_title('Observed data')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this model, instead of specifyng a likelihood function, we use `pm.Simulator()`, a \"container\" that stores the simulator function and the observed data. During sampling, samples from a and b priors will be passed to the simulator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    \n",
    "    a = pm.Normal('a', mu=1, sd=5)\n",
    "    b = pm.Normal('b', mu=1, sd=5)\n",
    "\n",
    "    simulator = pm.Simulator('simulator', competition_model, observed=observed)\n",
    "    \n",
    "    trace = pm.sample(step=pm.SMC(ABC=True, epsilon=1), draws=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "_, ax = plt.subplots(figsize=(14,6))\n",
    "ax.plot(observed[:,0], 'x', label='prey', c='C0')\n",
    "ax.plot(observed[:,1], 'x', label='predator', c='C1')\n",
    "ax.plot(competition_model(trace['a'].mean(), trace['b'].mean()), linewidth=2.5)\n",
    "for i in np.random.randint(0, size, 75):\n",
    "    ax.plot(competition_model(trace['a'][i], trace['b'][i])[:,0], alpha=0.1, c='C2', zorder=0)\n",
    "    ax.plot(competition_model(trace['a'][i], trace['b'][i])[:,1], alpha=0.1, c='C3', zorder=0)\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('population')\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
